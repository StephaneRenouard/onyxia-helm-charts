image:
  repository: harbor.lan/premyom/onyxia-s3-explorer
  tag: 0.1.6
  pullPolicy: IfNotPresent

imagePullSecrets:
  - name: harbor-regcred

# s3fs en pod Kubernetes nécessite FUSE: /dev/fuse + droits.
securityContext:
  privileged: true
  allowPrivilegeEscalation: true
  runAsUser: 0
  runAsGroup: 0
  capabilities:
    add:
      - SYS_ADMIN

resources:
  limits:
    cpu: "1"
    memory: 2Gi
  requests:
    cpu: "0.2"
    memory: 256Mi

# Vault (optionnel): laisse par défaut pour Arkam.
extraVault:
  addr: "http://vault.vault.svc.cluster.local:8200"
  k8sRole: "premyom-s3-read"

# Variables d'environnement additionnelles (optionnel).
# Les variables Premyom (Vault + S3 + groupes) sont définies directement dans le template Helm.
extraEnvVars: []

premyom:
  userGroupsJson: "[]"
  s3Mount:
    enabled: "true"
    nonHdsEndpointHost: "cellar-c2.services.clever-cloud.com"
    hdsEndpointHost: "cellar-c2.services.clever-cloud.com"
    vaultNonHdsPath: "secret/data/premyom/s3/nonhds"
    vaultHdsPath: "secret/data/premyom/s3/hds"
    mountRoot: "/mnt/s3"

sso:
  # `embedded` par défaut: évite les surprises liées au middleware forwardAuth (401/403)
  # et garde un comportement similaire au workspace `premyom-code-server`.
  # Les uploads TUS sont exposés via un Ingress dédié `/api/tus` vers Filebrowser (sans SSO).
  mode: embedded
  forwardAuth:
    middleware: onyxia-workspace-sso-chain@kubernetescrd

  secretName: oauth2-proxy
  issuerUrl: https://auth.datalab.arkam-group.com/auth/realms/onyxia
  redirectUrl: "https://datalab.arkam-group.com/oauth2/callback"
  cookieDomain: .datalab.arkam-group.com
  whitelistDomain: .datalab.arkam-group.com
  ingress:
    enabled: true
    tls: true
    ingressClassName: ""
    annotations:
      kubernetes.io/ingress.class: arkam-traefik
      traefik.ingress.kubernetes.io/router.entrypoints: websecure
      traefik.ingress.kubernetes.io/router.tls: "true"
      traefik.ingress.kubernetes.io/router.tls.certresolver: le
    hostname: chart-example.local
    path: /
